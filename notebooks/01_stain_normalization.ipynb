{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 01 â€“ Stain Normalization & Cell Segmentation\n",
    "\n",
    "This notebook performs:\n",
    "1. **Stain normalization** using Macenko/Vahadane method (automated, no manual region selection)\n",
    "2. **Cell segmentation** using InstanSeg or classical methods\n",
    "3. **Marker detection** for insulin, glucagon, CD3 (for fluorescence images)\n",
    "4. **Comprehensive visualizations** with full-image and close-up views\n",
    "\n",
    "Supports both brightfield and fluorescent multiplex images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Allow very large whole-slide images\n",
    "os.environ.setdefault('OPENCV_IO_MAX_IMAGE_PIXELS', str(2**63 - 1))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage import exposure\n",
    "\n",
    "try:\n",
    "    import openslide\n",
    "    _OPENSLIDE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    openslide = None\n",
    "    _OPENSLIDE_AVAILABLE = False\n",
    "    print('OpenSlide not available; WSI formats may not load')\n",
    "\n",
    "from isletscope.stain import StainNormalizer\n",
    "from isletscope.segmentation import CellSegmenter\n",
    "\n",
    "print('Imports complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Input Configuration =====\n",
    "image_path = '../images/129753.svs'  # Update to your file\n",
    "max_dimension = 12000  # Downsample WSI to this max dimension\n",
    "image_type = 'brightfield'  # 'brightfield' or 'fluorescence'\n",
    "\n",
    "# ===== Stain Normalization =====\n",
    "use_stain_norm = True\n",
    "stain_method = 'macenko'  # 'macenko' or 'vahadane'\n",
    "use_gpu = False  # Set True if CuPy installed\n",
    "\n",
    "# ===== Segmentation =====\n",
    "backend = 'instanseg'  # 'instanseg', 'model', or 'classical'\n",
    "probability_threshold = 0.5\n",
    "min_cell_size = 32  # Remove objects smaller than this\n",
    "\n",
    "# ===== InstanSeg Parameters =====\n",
    "# Model selection\n",
    "instanseg_model = 'brightfield_nuclei'  # 'brightfield_nuclei' or 'fluorescence_nuclei_and_cells'\n",
    "\n",
    "# Tiling parameters for large images (important for WSI)\n",
    "tile_size = 1024  # Tile size in pixels (512, 1024, or 2048)\n",
    "tile_overlap = 64  # Overlap between tiles (prevents edge artifacts)\n",
    "\n",
    "# Performance parameters\n",
    "batch_size = 4  # Number of tiles to process in parallel (GPU-dependent)\n",
    "pixel_size = None  # Physical pixel size in microns (auto-detected if None)\n",
    "normalization = True  # Apply intensity normalization\n",
    "image_reader = 'tiffslide'  # Image reading backend ('tiffslide', 'openslide')\n",
    "\n",
    "# ===== Marker Detection (for fluorescence) =====\n",
    "marker_channels = {'insulin': 0, 'glucagon': 1, 'CD3': 2}\n",
    "marker_thresholds = {'insulin': 80, 'glucagon': 80, 'CD3': 40}\n",
    "\n",
    "# ===== Visualization =====\n",
    "# Closeup regions (y_start, y_end, x_start, x_end) as fractions of image dimensions\n",
    "closeup_regions = [\n",
    "    (0.3, 0.4, 0.5, 0.6),  # Region 1\n",
    "    (0.6, 0.7, 0.7, 0.8),  # Region 2\n",
    "]\n",
    "\n",
    "# ===== Output =====\n",
    "output_dir = Path('../outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print('Configuration set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str, max_dim: int = 2000):\n",
    "    \"\"\"Load image; for WSI use OpenSlide at downsampled level.\"\"\"\n",
    "    p = Path(path)\n",
    "    suffix = p.suffix.lower()\n",
    "    \n",
    "    if _OPENSLIDE_AVAILABLE and suffix in {'.svs', '.tif', '.tiff', '.ndpi', '.scn'}:\n",
    "        slide = openslide.OpenSlide(str(p))\n",
    "        level = len(slide.level_dimensions) - 1\n",
    "        for i, (w, h) in enumerate(slide.level_dimensions):\n",
    "            if max(w, h) <= max_dim:\n",
    "                level = i\n",
    "                break\n",
    "        region = slide.read_region((0, 0), level, slide.level_dimensions[level])\n",
    "        img = cv2.cvtColor(np.array(region.convert('RGB')), cv2.COLOR_RGB2BGR)\n",
    "        slide.close()\n",
    "        return img\n",
    "    \n",
    "    img = cv2.imread(str(p))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f'Cannot load image: {path}')\n",
    "    return img\n",
    "\n",
    "def get_closeup_coords(img_shape, region_frac):\n",
    "    \"\"\"Convert fractional coordinates to pixel coordinates.\"\"\"\n",
    "    h, w = img_shape[:2]\n",
    "    y1, y2, x1, x2 = region_frac\n",
    "    return (int(y1*h), int(y2*h), int(x1*w), int(x2*w))\n",
    "\n",
    "print('Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = load_image(image_path, max_dim=max_dimension)\n",
    "print(f'Loaded image: {img_original.shape} ({img_original.dtype})')\n",
    "print(f'Image size: {img_original.shape[1]} x {img_original.shape[0]} pixels')\n",
    "print(f'Memory: {img_original.nbytes / 1e6:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norm-header",
   "metadata": {},
   "source": [
    "## Stain Normalization\n",
    "\n",
    "Automated stain vector estimation and normalization (no manual region selection required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_stain_norm and image_type == 'brightfield':\n",
    "    print(f'Running {stain_method} normalization...')\n",
    "    normalizer = StainNormalizer(method=stain_method, use_gpu=use_gpu)\n",
    "    normalizer.estimate_stain_matrix(img_original)\n",
    "    img_normalized = normalizer.normalize(img_original)\n",
    "    print('Stain normalization complete')\n",
    "else:\n",
    "    img_normalized = img_original.copy()\n",
    "    print('Skipping stain normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-norm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full image comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axes[0].imshow(cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Stain Normalized', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Draw rectangles showing closeup regions\n",
    "for i, region_frac in enumerate(closeup_regions):\n",
    "    y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n",
    "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='red', facecolor='none')\n",
    "    axes[1].add_patch(rect)\n",
    "    axes[1].text(x1, y1-10, f'Region {i+1}', color='red', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '01_stain_normalization_full.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-norm-closeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeup comparison\n",
    "n_regions = len(closeup_regions)\n",
    "fig, axes = plt.subplots(n_regions, 2, figsize=(12, 6*n_regions))\n",
    "if n_regions == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, region_frac in enumerate(closeup_regions):\n",
    "    y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n",
    "    \n",
    "    orig_crop = img_original[y1:y2, x1:x2]\n",
    "    norm_crop = img_normalized[y1:y2, x1:x2]\n",
    "    \n",
    "    axes[i, 0].imshow(cv2.cvtColor(orig_crop, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].set_title(f'Region {i+1} - Original', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(cv2.cvtColor(norm_crop, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 1].set_title(f'Region {i+1} - Normalized', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '01_stain_normalization_closeup.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seg-header",
   "metadata": {},
   "source": [
    "## Cell Segmentation\n",
    "\n",
    "Segment individual cells/nuclei using InstanSeg or classical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Running {backend} segmentation...')\n",
    "segmenter = CellSegmenter(\n",
    "    backend=backend,\n",
    "    use_instanseg=(backend == 'instanseg'),\n",
    "    probability_threshold=probability_threshold,\n",
    "    min_size=min_cell_size,\n",
    "    # InstanSeg-specific parameters\n",
    "    instanseg_model_name=instanseg_model,\n",
    "    tile_size=tile_size,\n",
    "    tile_overlap=tile_overlap,\n",
    "    batch_size=batch_size,\n",
    "    pixel_size=pixel_size,\n",
    "    normalization=normalization,\n",
    "    image_reader=image_reader,\n",
    ")\n",
    "\n",
    "seg_result = segmenter.segment(img_normalized, image_type=image_type)\n",
    "cell_mask = seg_result['mask']\n",
    "cell_labels = seg_result['labels']\n",
    "\n",
    "n_cells = cell_labels.max()\n",
    "print(f'Segmentation complete: {n_cells:,} cells detected')\n",
    "print(f'Total cell area: {cell_mask.sum():,} pixels ({100*cell_mask.sum()/cell_mask.size:.1f}% of image)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "markers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker detection (fluorescence only)\n",
    "markers = {}\n",
    "if image_type == 'fluorescence' and marker_channels:\n",
    "    print('Detecting markers...')\n",
    "    markers = segmenter.detect_markers(\n",
    "        img_normalized,\n",
    "        cell_labels,\n",
    "        marker_channels=marker_channels,\n",
    "        thresholds=marker_thresholds,\n",
    "        brighter_is_positive=True\n",
    "    )\n",
    "    for marker, mask in markers.items():\n",
    "        print(f'  {marker}: {int(mask.sum())} positive cells')\n",
    "else:\n",
    "    print('Skipping marker detection (brightfield image)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-seg-full",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full image segmentation overlay\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original/normalized\n",
    "axes[0].imshow(cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Normalized Image', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Cell mask\n",
    "axes[1].imshow(cell_mask, cmap='gray')\n",
    "axes[1].set_title(f'Cell Mask ({n_cells} cells)', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "overlay = cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB).copy()\n",
    "overlay[cell_mask > 0] = overlay[cell_mask > 0] * 0.6 + np.array([255, 0, 0]) * 0.4\n",
    "axes[2].imshow(overlay)\n",
    "axes[2].set_title('Segmentation Overlay', fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Draw closeup region boxes\n",
    "for i, region_frac in enumerate(closeup_regions):\n",
    "    y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n",
    "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='yellow', facecolor='none')\n",
    "    axes[2].add_patch(rect)\n",
    "    axes[2].text(x1, y1-10, f'Region {i+1}', color='yellow', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '02_cell_segmentation_full.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-seg-closeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeup segmentation views\n",
    "fig, axes = plt.subplots(n_regions, 3, figsize=(15, 5*n_regions))\n",
    "if n_regions == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, region_frac in enumerate(closeup_regions):\n",
    "    y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n",
    "    \n",
    "    img_crop = img_normalized[y1:y2, x1:x2]\n",
    "    mask_crop = cell_mask[y1:y2, x1:x2]\n",
    "    labels_crop = cell_labels[y1:y2, x1:x2]\n",
    "    \n",
    "    # Image\n",
    "    axes[i, 0].imshow(cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].set_title(f'Region {i+1} - Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Labels (colored)\n",
    "    from skimage.color import label2rgb\n",
    "    labels_colored = label2rgb(labels_crop, bg_label=0)\n",
    "    axes[i, 1].imshow(labels_colored)\n",
    "    axes[i, 1].set_title(f'Region {i+1} - Cell Labels ({labels_crop.max()} cells)', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Overlay with boundaries\n",
    "    from skimage.segmentation import find_boundaries\n",
    "    overlay_crop = cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB).copy()\n",
    "    boundaries = find_boundaries(labels_crop, mode='thick')\n",
    "    overlay_crop[boundaries] = [255, 255, 0]  # Yellow boundaries\n",
    "    axes[i, 2].imshow(overlay_crop)\n",
    "    axes[i, 2].set_title(f'Region {i+1} - Cell Boundaries', fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '02_cell_segmentation_closeup.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs for next notebook\n",
    "np.save(output_dir / 'img_normalized.npy', img_normalized)\n",
    "np.save(output_dir / 'cell_mask.npy', cell_mask)\n",
    "np.save(output_dir / 'cell_labels.npy', cell_labels)\n",
    "\n",
    "if markers:\n",
    "    for marker, mask in markers.items():\n",
    "        np.save(output_dir / f'marker_{marker}.npy', mask)\n",
    "\n",
    "print(f'Results saved to {output_dir}')\n",
    "print('\\nReady for notebook 02: Islet Detection & Radial Analysis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isletscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
