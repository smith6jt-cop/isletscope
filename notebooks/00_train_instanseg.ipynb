{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 – InstanSeg Model Training\n",
    "\n",
    "This notebook allows you to:\n",
    "1. **Prepare training datasets** from annotated images\n",
    "2. **Fine-tune existing InstanSeg models** on custom data\n",
    "3. **Train new InstanSeg models** from scratch\n",
    "4. **Validate and export trained models** for use in other notebooks\n",
    "\n",
    "**Use Cases**:\n",
    "- Custom pancreatic tissue that doesn't segment well with pretrained models\n",
    "- Specialized staining protocols (custom H&E, immunofluorescence panels)\n",
    "- Domain adaptation for tissue-specific cell morphologies\n",
    "\n",
    "**Requirements**:\n",
    "- Annotated training images (masks with instance labels)\n",
    "- InstanSeg installed: `pip install instanseg-torch[full]`\n",
    "- GPU recommended for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "\n",
    "# Import InstanSeg training utilities\n",
    "try:\n",
    "    from instanseg import InstanSeg\n",
    "    from instanseg.utils.augmentation import Augmenter\n",
    "    print('InstanSeg imported successfully')\n",
    "except ImportError as e:\n",
    "    print(f'Error importing InstanSeg: {e}')\n",
    "    print('Install with: pip install instanseg-torch[full]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Dataset Configuration =====\n",
    "# Directory containing training images and masks\n",
    "dataset_dir = Path('../data/training')\n",
    "images_dir = dataset_dir / 'images'  # RGB images\n",
    "masks_dir = dataset_dir / 'masks'    # Instance label masks\n",
    "\n",
    "# Create directories if they don't exist\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "masks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== Training Configuration =====\n",
    "# Base model to fine-tune (or None to train from scratch)\n",
    "base_model = 'brightfield_nuclei'  # 'brightfield_nuclei', 'fluorescence_nuclei_and_cells', or None\n",
    "\n",
    "# Training parameters\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "patch_size = 512  # Size of training patches\n",
    "val_split = 0.2   # Fraction of data for validation\n",
    "\n",
    "# Data augmentation\n",
    "use_augmentation = True\n",
    "augmentation_params = {\n",
    "    'rotation': True,\n",
    "    'flip': True,\n",
    "    'scale': (0.8, 1.2),\n",
    "    'elastic_deformation': True,\n",
    "    'brightness': 0.2,\n",
    "    'contrast': 0.2,\n",
    "}\n",
    "\n",
    "# ===== Output Configuration =====\n",
    "output_dir = Path('../models/instanseg_custom')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = 'pancreas_brightfield_v1'\n",
    "checkpoint_interval = 10  # Save checkpoint every N epochs\n",
    "\n",
    "print('Configuration set')\n",
    "print(f'Dataset: {dataset_dir}')\n",
    "print(f'Output: {output_dir / model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "**Expected Format**:\n",
    "- Images: RGB or grayscale images (PNG, TIFF, or JPG)\n",
    "- Masks: 16-bit or 32-bit integer arrays where each unique value represents a cell instance\n",
    "  - Background = 0\n",
    "  - Cell 1 = 1, Cell 2 = 2, etc.\n",
    "\n",
    "**Annotation Tools**:\n",
    "- **QuPath**: Export instance segmentation masks\n",
    "- **Cellpose**: Use GUI to annotate and export masks\n",
    "- **CVAT/Label Studio**: Polygon annotations → convert to instance masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(images_dir, masks_dir):\n",
    "    \"\"\"Load all images and corresponding masks.\"\"\"\n",
    "    image_files = sorted(images_dir.glob('*.png')) + sorted(images_dir.glob('*.tif')) + sorted(images_dir.glob('*.tiff'))\n",
    "    \n",
    "    dataset = []\n",
    "    for img_path in image_files:\n",
    "        # Find corresponding mask\n",
    "        mask_path = masks_dir / f'{img_path.stem}_mask.tif'\n",
    "        if not mask_path.exists():\n",
    "            mask_path = masks_dir / f'{img_path.stem}.tif'\n",
    "        if not mask_path.exists():\n",
    "            print(f'Warning: No mask found for {img_path.name}')\n",
    "            continue\n",
    "        \n",
    "        dataset.append({'image': img_path, 'mask': mask_path})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def visualize_sample(dataset, idx=0):\n",
    "    \"\"\"Visualize a sample from the dataset.\"\"\"\n",
    "    sample = dataset[idx]\n",
    "    img = cv2.imread(str(sample['image']))\n",
    "    mask = cv2.imread(str(sample['mask']), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Image', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask > 0, cmap='gray')\n",
    "    axes[1].set_title('Binary Mask', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    from skimage.color import label2rgb\n",
    "    colored_mask = label2rgb(mask, bg_label=0)\n",
    "    axes[2].imshow(colored_mask)\n",
    "    n_cells = len(np.unique(mask)) - 1\n",
    "    axes[2].set_title(f'Instance Labels ({n_cells} cells)', fontsize=14, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(images_dir, masks_dir)\n",
    "print(f'Loaded {len(dataset)} image-mask pairs')\n",
    "\n",
    "if len(dataset) > 0:\n",
    "    print('\\nDataset statistics:')\n",
    "    total_cells = 0\n",
    "    for sample in dataset:\n",
    "        mask = cv2.imread(str(sample['mask']), cv2.IMREAD_UNCHANGED)\n",
    "        n_cells = len(np.unique(mask)) - 1\n",
    "        total_cells += n_cells\n",
    "    print(f'  Total cells: {total_cells:,}')\n",
    "    print(f'  Avg cells per image: {total_cells / len(dataset):.0f}')\n",
    "    \n",
    "    # Visualize first sample\n",
    "    print('\\nVisualizing first sample:')\n",
    "    visualize_sample(dataset, idx=0)\n",
    "else:\n",
    "    print('\\n⚠ No training data found!')\n",
    "    print(f'Add annotated images to: {images_dir}')\n",
    "    print(f'Add corresponding masks to: {masks_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Augmentation improves model generalization by creating variations of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmenter(params):\n",
    "    \"\"\"Create augmentation pipeline.\"\"\"\n",
    "    transforms = []\n",
    "    \n",
    "    if params.get('rotation'):\n",
    "        transforms.append('rotation')\n",
    "    if params.get('flip'):\n",
    "        transforms.append('flip')\n",
    "    if params.get('scale'):\n",
    "        transforms.append(('scale', params['scale']))\n",
    "    if params.get('elastic_deformation'):\n",
    "        transforms.append('elastic')\n",
    "    if params.get('brightness'):\n",
    "        transforms.append(('brightness', params['brightness']))\n",
    "    if params.get('contrast'):\n",
    "        transforms.append(('contrast', params['contrast']))\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def augment_sample(img, mask, transforms):\n",
    "    \"\"\"Apply augmentation transforms.\"\"\"\n",
    "    # Basic augmentations using numpy/cv2\n",
    "    # (Real implementation would use albumentations or similar)\n",
    "    \n",
    "    # Random rotation\n",
    "    if 'rotation' in transforms and np.random.rand() > 0.5:\n",
    "        angle = np.random.uniform(-180, 180)\n",
    "        h, w = img.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "        mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Random flip\n",
    "    if 'flip' in transforms:\n",
    "        if np.random.rand() > 0.5:\n",
    "            img = cv2.flip(img, 0)  # vertical\n",
    "            mask = cv2.flip(mask, 0)\n",
    "        if np.random.rand() > 0.5:\n",
    "            img = cv2.flip(img, 1)  # horizontal\n",
    "            mask = cv2.flip(mask, 1)\n",
    "    \n",
    "    return img, mask\n",
    "\n",
    "# Test augmentation on first sample\n",
    "if len(dataset) > 0 and use_augmentation:\n",
    "    sample = dataset[0]\n",
    "    img = cv2.imread(str(sample['image']))\n",
    "    mask = cv2.imread(str(sample['mask']), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    transforms = create_augmenter(augmentation_params)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    for i in range(4):\n",
    "        img_aug, mask_aug = augment_sample(img.copy(), mask.copy(), transforms)\n",
    "        \n",
    "        axes[0, i].imshow(cv2.cvtColor(img_aug, cv2.COLOR_BGR2RGB))\n",
    "        axes[0, i].set_title(f'Augmented {i+1}', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        from skimage.color import label2rgb\n",
    "        colored = label2rgb(mask_aug, bg_label=0)\n",
    "        axes[1, i].imshow(colored)\n",
    "        axes[1, i].set_title(f'Mask {i+1}', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "**Note**: This cell provides a training template. InstanSeg's training API may require adjustment based on the installed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_instanseg_model(\n",
    "    dataset,\n",
    "    base_model=None,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    learning_rate=1e-4,\n",
    "    patch_size=512,\n",
    "    val_split=0.2,\n",
    "    output_dir=None,\n",
    "    checkpoint_interval=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train InstanSeg model.\n",
    "    \n",
    "    This is a template - adjust based on InstanSeg's actual training API.\n",
    "    Consult InstanSeg documentation for the exact training procedure.\n",
    "    \"\"\"\n",
    "    print('=' * 60)\n",
    "    print('Training Configuration:')\n",
    "    print(f'  Base model: {base_model or \"from scratch\"}')\n",
    "    print(f'  Dataset size: {len(dataset)} samples')\n",
    "    print(f'  Epochs: {epochs}')\n",
    "    print(f'  Batch size: {batch_size}')\n",
    "    print(f'  Learning rate: {learning_rate}')\n",
    "    print(f'  Patch size: {patch_size}x{patch_size}')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Split dataset\n",
    "    n_val = int(len(dataset) * val_split)\n",
    "    n_train = len(dataset) - n_val\n",
    "    \n",
    "    indices = np.random.permutation(len(dataset))\n",
    "    train_indices = indices[:n_train]\n",
    "    val_indices = indices[n_train:]\n",
    "    \n",
    "    print(f'\\nTrain samples: {n_train}')\n",
    "    print(f'Val samples: {n_val}')\n",
    "    \n",
    "    # Initialize or load model\n",
    "    if base_model:\n",
    "        print(f'\\nLoading base model: {base_model}')\n",
    "        model = InstanSeg(base_model)\n",
    "    else:\n",
    "        print('\\nInitializing model from scratch')\n",
    "        # Model architecture initialization would go here\n",
    "        raise NotImplementedError(\n",
    "            'Training from scratch requires model architecture definition. '\n",
    "            'Consult InstanSeg documentation for model initialization.'\n",
    "        )\n",
    "    \n",
    "    # Training loop\n",
    "    print('\\nStarting training...')\n",
    "    \n",
    "    # NOTE: InstanSeg may have a built-in training method like:\n",
    "    # model.train(\n",
    "    #     train_data=train_dataset,\n",
    "    #     val_data=val_dataset,\n",
    "    #     epochs=epochs,\n",
    "    #     batch_size=batch_size,\n",
    "    #     learning_rate=learning_rate,\n",
    "    #     ...\n",
    "    # )\n",
    "    \n",
    "    print('\\n⚠ Training template requires InstanSeg training API.')\n",
    "    print('Consult InstanSeg documentation for:')\n",
    "    print('  - model.fit() or model.train() method')\n",
    "    print('  - Dataset format (PyTorch Dataset/DataLoader)')\n",
    "    print('  - Loss functions and optimizers')\n",
    "    print('  - Checkpoint saving')\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Run training (if dataset is available)\n",
    "if len(dataset) >= 5:  # Minimum samples for meaningful training\n",
    "    trained_model = train_instanseg_model(\n",
    "        dataset=dataset,\n",
    "        base_model=base_model,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        patch_size=patch_size,\n",
    "        val_split=val_split,\n",
    "        output_dir=output_dir,\n",
    "        checkpoint_interval=checkpoint_interval,\n",
    "    )\n",
    "else:\n",
    "    print('⚠ Insufficient training data (need at least 5 samples)')\n",
    "    print(f'Current: {len(dataset)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "Test the trained model on validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = output_dir / model_name / 'final_model.pth'\n",
    "\n",
    "if model_path.exists():\n",
    "    print(f'Loading model: {model_path}')\n",
    "    # model = InstanSeg.load(model_path)\n",
    "    print('Model loaded successfully')\n",
    "    \n",
    "    # Run inference on validation samples\n",
    "    # ... validation code ...\n",
    "else:\n",
    "    print(f'⚠ Model not found: {model_path}')\n",
    "    print('Train a model first or specify an existing model path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for Production\n",
    "\n",
    "Save the trained model in a format compatible with notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "export_path = output_dir / f'{model_name}_export'\n",
    "export_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(f'Exporting model to: {export_path}')\n",
    "print('\\nTo use in notebook 01, set:')\n",
    "print(f\"  instanseg_model = '{export_path}'\")\n",
    "print('  backend = \\'instanseg\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a framework for training custom InstanSeg models. Key steps:\n",
    "\n",
    "1. **Prepare annotated data** (images + instance masks)\n",
    "2. **Configure training parameters** (epochs, batch size, learning rate)\n",
    "3. **Train model** (fine-tune pretrained or train from scratch)\n",
    "4. **Validate performance** on held-out test set\n",
    "5. **Export model** for use in production notebooks\n",
    "\n",
    "**Next Steps**:\n",
    "- Collect more training data for better generalization\n",
    "- Experiment with hyperparameters\n",
    "- Test on diverse tissue samples\n",
    "- Compare with pretrained models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
