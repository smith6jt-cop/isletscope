{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# 01 â€“ Enhanced Nuclear Segmentation\n\nThis notebook performs:\n1. **Enhanced Nuclear Preprocessing** using true hematoxylin channel extraction (color deconvolution)\n2. **Contrast Enhancement** via CLAHE for optimal nuclear visibility\n3. **Cell segmentation** using multiple backends:\n   - `hematoxylin_watershed` - Recommended for H&E (robust, no ML required)\n   - `hematoxylin_instanseg` - Best quality when InstanSeg is available\n   - `hematoxylin_adaptive` - Fastest option for well-stained samples\n   - `instanseg` - Original InstanSeg on RGB (legacy)\n   - `classical` - Simple thresholding (fallback)\n4. **Marker detection** for insulin, glucagon, CD3 (for fluorescence images)\n5. **Comprehensive visualizations** with preprocessing steps and results\n\n**Key Improvement**: Instead of using stain normalization (which standardizes colors but doesn't\nseparate stains), we now use true **color deconvolution** to extract the hematoxylin channel\nspecifically. This isolates the nuclear signal for much better segmentation quality.\n\nSupports both brightfield and fluorescent multiplex images."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Allow very large whole-slide images\nos.environ.setdefault('OPENCV_IO_MAX_IMAGE_PIXELS', str(2**63 - 1))\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom skimage import exposure\n\ntry:\n    import openslide\n    _OPENSLIDE_AVAILABLE = True\nexcept ImportError:\n    openslide = None\n    _OPENSLIDE_AVAILABLE = False\n    print('OpenSlide not available; WSI formats may not load')\n\nfrom isletscope.stain import StainNormalizer\nfrom isletscope.segmentation import CellSegmenter\n\n# Import enhanced nuclear segmentation (for visualization)\ntry:\n    from isletscope.nuclear_segmentation import NuclearPreprocessor\n    _NUCLEAR_SEG_AVAILABLE = True\n    print('Enhanced nuclear segmentation available')\nexcept ImportError:\n    _NUCLEAR_SEG_AVAILABLE = False\n    print('Enhanced nuclear segmentation not available (install scipy, scikit-image)')\n\nprint('Imports complete')"
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "# ===== Input Configuration =====\nimage_path = '../images/129753.svs'  # Update to your file\nmax_dimension = 2000  # Downsample WSI to this max dimension\nimage_type = 'brightfield'  # 'brightfield' or 'fluorescence'\n\n# ===== Stain Normalization (Optional - legacy approach) =====\n# Note: For enhanced backends (hematoxylin_*), stain normalization is NOT needed\n# as they use true color deconvolution to extract the hematoxylin channel directly.\nuse_stain_norm = False  # Set to False when using hematoxylin_* backends\nstain_method = 'macenko'  # 'macenko' or 'vahadane'\nuse_gpu = False  # Set True if CuPy installed\n\n# ===== Tissue Detection =====\n# IMPORTANT: Detect tissue boundaries BEFORE cell segmentation to avoid false positives on glass/background\ndetect_tissue_first = True  # Recommended: True\ntissue_detection_method = 'otsu'  # 'otsu' (recommended), 'brightness', or 'saturation'\n\n# ===== Segmentation Backend =====\n# RECOMMENDED for brightfield H&E: 'hematoxylin_watershed' (robust, no ML required)\n# Options:\n#   - 'hematoxylin_watershed': Hematoxylin extraction + CLAHE + watershed (RECOMMENDED)\n#   - 'hematoxylin_instanseg': Hematoxylin extraction + CLAHE + InstanSeg (best with GPU)\n#   - 'hematoxylin_adaptive': Hematoxylin extraction + adaptive threshold (fastest)\n#   - 'instanseg': Original InstanSeg on RGB (legacy)\n#   - 'classical': Simple thresholding (fallback)\n#   - 'auto': Auto-select best available backend\nbackend = 'hematoxylin_watershed'  # RECOMMENDED for brightfield H&E\n\n# ===== Common Segmentation Parameters =====\nmin_cell_size = 32  # Remove objects smaller than this (in pixels)\nmax_cell_size = 5000  # Remove objects larger than this (in pixels)\n\n# ===== Enhanced Nuclear Segmentation Parameters =====\n# (used by hematoxylin_* backends)\nstain_matrix = 'he_standard'  # 'he_standard', 'he_ruifrok', or 'dab'\nclahe_clip_limit = 3.0  # CLAHE contrast enhancement (higher = more contrast)\nmin_distance = 10  # Minimum distance between nuclei for watershed\n\n# ===== InstanSeg Parameters =====\n# (used by 'instanseg' and 'hematoxylin_instanseg' backends)\ninstanseg_model = 'brightfield_nuclei'  # 'brightfield_nuclei' or 'fluorescence_nuclei_and_cells'\ntile_size = 1024  # Tile size in pixels (512, 1024, or 2048)\ntile_overlap = 64  # Overlap between tiles (prevents edge artifacts)\nbatch_size = 4  # Number of tiles to process in parallel (GPU-dependent)\npixel_size = None  # Physical pixel size in microns (auto-detected if None)\nnormalization = True  # Apply intensity normalization\nimage_reader = 'tiffslide'  # Image reading backend ('tiffslide', 'openslide')\n\n# Legacy parameters (for 'classical' backend only)\nprobability_threshold = 0.5  # NOT used by InstanSeg or enhanced backends\n\n# ===== Marker Detection (for fluorescence) =====\nmarker_channels = {'insulin': 0, 'glucagon': 1, 'CD3': 2}\nmarker_thresholds = {'insulin': 80, 'glucagon': 80, 'CD3': 40}\n\n# ===== Visualization =====\n# Closeup regions (y_start, y_end, x_start, x_end) as fractions of image dimensions\ncloseup_regions = [\n    (0.2, 0.4, 0.3, 0.5),  # Region 1\n    (0.5, 0.7, 0.6, 0.8),  # Region 2\n]\n\n# ===== Output =====\noutput_dir = Path('../outputs')\noutput_dir.mkdir(exist_ok=True)\n\nprint('Configuration set')\nprint(f'Using backend: {backend}')"
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str, max_dim: int = 2000):\n",
    "    \"\"\"Load image; for WSI use OpenSlide at downsampled level.\"\"\"\n",
    "    p = Path(path)\n",
    "    suffix = p.suffix.lower()\n",
    "    \n",
    "    if _OPENSLIDE_AVAILABLE and suffix in {'.svs', '.tif', '.tiff', '.ndpi', '.scn'}:\n",
    "        slide = openslide.OpenSlide(str(p))\n",
    "        level = len(slide.level_dimensions) - 1\n",
    "        for i, (w, h) in enumerate(slide.level_dimensions):\n",
    "            if max(w, h) <= max_dim:\n",
    "                level = i\n",
    "                break\n",
    "        region = slide.read_region((0, 0), level, slide.level_dimensions[level])\n",
    "        img = cv2.cvtColor(np.array(region.convert('RGB')), cv2.COLOR_RGB2BGR)\n",
    "        slide.close()\n",
    "        return img\n",
    "    \n",
    "    img = cv2.imread(str(p))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f'Cannot load image: {path}')\n",
    "    return img\n",
    "\n",
    "def get_closeup_coords(img_shape, region_frac):\n",
    "    \"\"\"Convert fractional coordinates to pixel coordinates.\"\"\"\n",
    "    h, w = img_shape[:2]\n",
    "    y1, y2, x1, x2 = region_frac\n",
    "    return (int(y1*h), int(y2*h), int(x1*w), int(x2*w))\n",
    "\n",
    "print('Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_original = load_image(image_path, max_dim=max_dimension)\n",
    "print(f'Loaded image: {img_original.shape} ({img_original.dtype})')\n",
    "print(f'Image size: {img_original.shape[1]} x {img_original.shape[0]} pixels')\n",
    "print(f'Memory: {img_original.nbytes / 1e6:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norm-header",
   "metadata": {},
   "source": "## Preprocessing\n\nFor **hematoxylin_* backends**: We use true color deconvolution to extract the hematoxylin channel\n(nuclear signal), then apply CLAHE for contrast enhancement. This is more effective than standard\nstain normalization because it isolates the nuclear signal rather than just standardizing colors.\n\nFor **legacy backends** (instanseg, classical): Optional Macenko/Vahadane stain normalization."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": "# Preprocessing depends on the backend chosen\nis_hematoxylin_backend = backend.startswith('hematoxylin_')\n\nif is_hematoxylin_backend and _NUCLEAR_SEG_AVAILABLE:\n    # Enhanced preprocessing: hematoxylin extraction + CLAHE\n    print('Running enhanced nuclear preprocessing (hematoxylin extraction + CLAHE)...')\n    preprocessor = NuclearPreprocessor(\n        stain_matrix=stain_matrix,\n        clahe_clip_limit=clahe_clip_limit,\n    )\n    prep_result = preprocessor.preprocess(img_original, return_intermediate=True)\n    hematoxylin_channel = prep_result['hematoxylin']\n    eosin_channel = prep_result['eosin']\n    enhanced_channel = prep_result['enhanced']\n    img_normalized = img_original.copy()  # Keep original for visualization\n    print('  Hematoxylin channel extracted')\n    print('  CLAHE contrast enhancement applied')\n    print('Enhanced preprocessing complete')\n    \nelif use_stain_norm and image_type == 'brightfield':\n    # Legacy preprocessing: Macenko/Vahadane stain normalization\n    print(f'Running {stain_method} normalization...')\n    normalizer = StainNormalizer(method=stain_method, use_gpu=use_gpu)\n    normalizer.estimate_stain_matrix(img_original)\n    img_normalized = normalizer.normalize(img_original)\n    hematoxylin_channel = None\n    eosin_channel = None\n    enhanced_channel = None\n    print('Stain normalization complete')\nelse:\n    img_normalized = img_original.copy()\n    hematoxylin_channel = None\n    eosin_channel = None\n    enhanced_channel = None\n    print('Skipping preprocessing')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-norm",
   "metadata": {},
   "outputs": [],
   "source": "# Visualization: Preprocessing results\nif hematoxylin_channel is not None:\n    # Enhanced preprocessing visualization (4 panels)\n    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n    \n    # Original image\n    axes[0, 0].imshow(cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB))\n    axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')\n    axes[0, 0].axis('off')\n    \n    # Hematoxylin channel (nuclei)\n    axes[0, 1].imshow(hematoxylin_channel, cmap='gray')\n    axes[0, 1].set_title('Hematoxylin Channel (Nuclei)', fontsize=14, fontweight='bold')\n    axes[0, 1].axis('off')\n    \n    # Eosin channel (cytoplasm/background)\n    axes[1, 0].imshow(eosin_channel, cmap='Reds')\n    axes[1, 0].set_title('Eosin Channel (Cytoplasm)', fontsize=14, fontweight='bold')\n    axes[1, 0].axis('off')\n    \n    # Enhanced (CLAHE) hematoxylin\n    axes[1, 1].imshow(enhanced_channel, cmap='gray')\n    axes[1, 1].set_title('Enhanced (CLAHE) Hematoxylin', fontsize=14, fontweight='bold')\n    axes[1, 1].axis('off')\n    \n    # Draw rectangles showing closeup regions on enhanced image\n    for i, region_frac in enumerate(closeup_regions):\n        y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='red', facecolor='none')\n        axes[1, 1].add_patch(rect)\n        axes[1, 1].text(x1, y1-10, f'Region {i+1}', color='red', fontsize=10, fontweight='bold')\n\nelse:\n    # Legacy stain normalization visualization (2 panels)\n    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n    axes[0].imshow(cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB))\n    axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n    axes[0].axis('off')\n    \n    axes[1].imshow(cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB))\n    axes[1].set_title('Stain Normalized', fontsize=14, fontweight='bold')\n    axes[1].axis('off')\n    \n    # Draw rectangles showing closeup regions\n    for i, region_frac in enumerate(closeup_regions):\n        y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n        rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='red', facecolor='none')\n        axes[1].add_patch(rect)\n        axes[1].text(x1, y1-10, f'Region {i+1}', color='red', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(output_dir / '01_preprocessing_full.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-norm-closeup",
   "metadata": {},
   "outputs": [],
   "source": "# Closeup preprocessing comparison\nn_regions = len(closeup_regions)\n\nif hematoxylin_channel is not None:\n    # Enhanced preprocessing closeups (3 columns: original, hematoxylin, enhanced)\n    fig, axes = plt.subplots(n_regions, 3, figsize=(15, 5*n_regions))\n    if n_regions == 1:\n        axes = axes.reshape(1, -1)\n    \n    for i, region_frac in enumerate(closeup_regions):\n        y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n        \n        orig_crop = img_original[y1:y2, x1:x2]\n        hema_crop = hematoxylin_channel[y1:y2, x1:x2]\n        enhanced_crop = enhanced_channel[y1:y2, x1:x2]\n        \n        axes[i, 0].imshow(cv2.cvtColor(orig_crop, cv2.COLOR_BGR2RGB))\n        axes[i, 0].set_title(f'Region {i+1} - Original', fontsize=12, fontweight='bold')\n        axes[i, 0].axis('off')\n        \n        axes[i, 1].imshow(hema_crop, cmap='gray')\n        axes[i, 1].set_title(f'Region {i+1} - Hematoxylin', fontsize=12, fontweight='bold')\n        axes[i, 1].axis('off')\n        \n        axes[i, 2].imshow(enhanced_crop, cmap='gray')\n        axes[i, 2].set_title(f'Region {i+1} - Enhanced (CLAHE)', fontsize=12, fontweight='bold')\n        axes[i, 2].axis('off')\n\nelse:\n    # Legacy stain normalization closeups (2 columns)\n    fig, axes = plt.subplots(n_regions, 2, figsize=(12, 6*n_regions))\n    if n_regions == 1:\n        axes = axes.reshape(1, -1)\n    \n    for i, region_frac in enumerate(closeup_regions):\n        y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n        \n        orig_crop = img_original[y1:y2, x1:x2]\n        norm_crop = img_normalized[y1:y2, x1:x2]\n        \n        axes[i, 0].imshow(cv2.cvtColor(orig_crop, cv2.COLOR_BGR2RGB))\n        axes[i, 0].set_title(f'Region {i+1} - Original', fontsize=12, fontweight='bold')\n        axes[i, 0].axis('off')\n        \n        axes[i, 1].imshow(cv2.cvtColor(norm_crop, cv2.COLOR_BGR2RGB))\n        axes[i, 1].set_title(f'Region {i+1} - Normalized', fontsize=12, fontweight='bold')\n        axes[i, 1].axis('off')\n\nplt.tight_layout()\nplt.savefig(output_dir / '01_preprocessing_closeup.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "seg-header",
   "metadata": {},
   "source": [
    "## Cell Segmentation\n",
    "\n",
    "Segment individual cells/nuclei using InstanSeg or classical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "segment",
   "metadata": {},
   "outputs": [],
   "source": "print(f'Running {backend} segmentation...')\nsegmenter = CellSegmenter(\n    backend=backend,\n    # Common parameters\n    min_size=min_cell_size,\n    max_size=max_cell_size,\n    # Enhanced nuclear segmentation parameters\n    stain_matrix=stain_matrix,\n    clahe_clip_limit=clahe_clip_limit,\n    min_distance=min_distance,\n    # InstanSeg parameters\n    use_instanseg=(backend in ['instanseg', 'hematoxylin_instanseg']),\n    instanseg_model_name=instanseg_model,\n    tile_size=tile_size,\n    tile_overlap=tile_overlap,\n    batch_size=batch_size,\n    pixel_size=pixel_size,\n    normalization=normalization,\n    image_reader=image_reader,\n    # Legacy parameters\n    probability_threshold=probability_threshold,\n)\n\n# Segment cells with tissue detection\n# Note: For hematoxylin_* backends, we pass the original image as preprocessing\n# is handled internally by the enhanced segmenter\nseg_result = segmenter.segment(\n    img_original,  # Use original image - preprocessing is done by backend\n    image_type=image_type,\n    detect_tissue_first=detect_tissue_first,\n)\n\ncell_mask = seg_result['mask']\ncell_labels = seg_result['labels']\ntissue_mask = seg_result.get('tissue_mask')\n\nn_cells = cell_labels.max()\nprint(f'\\nSegmentation complete: {n_cells:,} cells detected')\nprint(f'Total cell area: {cell_mask.sum():,} pixels ({100*cell_mask.sum()/cell_mask.size:.1f}% of image)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "markers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker detection (fluorescence only)\n",
    "markers = {}\n",
    "if image_type == 'fluorescence' and marker_channels:\n",
    "    print('Detecting markers...')\n",
    "    markers = segmenter.detect_markers(\n",
    "        img_normalized,\n",
    "        cell_labels,\n",
    "        marker_channels=marker_channels,\n",
    "        thresholds=marker_thresholds,\n",
    "        brighter_is_positive=True\n",
    "    )\n",
    "    for marker, mask in markers.items():\n",
    "        print(f'  {marker}: {int(mask.sum())} positive cells')\n",
    "else:\n",
    "    print('Skipping marker detection (brightfield image)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-seg-full",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full image segmentation overlay\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# Original/normalized\n",
    "axes[0, 0].imshow(cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Normalized Image', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Tissue mask\n",
    "if tissue_mask is not None:\n",
    "    axes[0, 1].imshow(tissue_mask, cmap='gray')\n",
    "    tissue_pct = 100 * tissue_mask.sum() / tissue_mask.size\n",
    "    axes[0, 1].set_title(f'Tissue Mask ({tissue_pct:.1f}% tissue)', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'No tissue mask', ha='center', va='center')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "# Cell mask\n",
    "axes[1, 0].imshow(cell_mask, cmap='gray')\n",
    "axes[1, 0].set_title(f'Cell Mask ({n_cells:,} cells)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Overlay\n",
    "overlay = cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB).copy()\n",
    "if tissue_mask is not None:\n",
    "    # Show tissue boundary in blue\n",
    "    tissue_boundary = cv2.Canny((tissue_mask * 255).astype(np.uint8), 100, 200)\n",
    "    overlay[tissue_boundary > 0] = [0, 0, 255]  # Blue tissue boundary\n",
    "# Show cells in red\n",
    "overlay[cell_mask > 0] = overlay[cell_mask > 0] * 0.6 + np.array([255, 0, 0]) * 0.4\n",
    "axes[1, 1].imshow(overlay)\n",
    "axes[1, 1].set_title('Tissue (blue) + Cells (red)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Draw closeup region boxes\n",
    "for i, region_frac in enumerate(closeup_regions):\n",
    "    y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n",
    "    rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='yellow', facecolor='none')\n",
    "    axes[1, 1].add_patch(rect)\n",
    "    axes[1, 1].text(x1, y1-10, f'Region {i+1}', color='yellow', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '02_cell_segmentation_full.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-seg-closeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeup segmentation views\n",
    "fig, axes = plt.subplots(n_regions, 3, figsize=(15, 5*n_regions))\n",
    "if n_regions == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, region_frac in enumerate(closeup_regions):\n",
    "    y1, y2, x1, x2 = get_closeup_coords(img_original.shape, region_frac)\n",
    "    \n",
    "    img_crop = img_normalized[y1:y2, x1:x2]\n",
    "    mask_crop = cell_mask[y1:y2, x1:x2]\n",
    "    labels_crop = cell_labels[y1:y2, x1:x2]\n",
    "    \n",
    "    # Image\n",
    "    axes[i, 0].imshow(cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].set_title(f'Region {i+1} - Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Labels (colored)\n",
    "    from skimage.color import label2rgb\n",
    "    labels_colored = label2rgb(labels_crop, bg_label=0)\n",
    "    axes[i, 1].imshow(labels_colored)\n",
    "    axes[i, 1].set_title(f'Region {i+1} - Cell Labels ({labels_crop.max()} cells)', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Overlay with boundaries\n",
    "    from skimage.segmentation import find_boundaries\n",
    "    overlay_crop = cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB).copy()\n",
    "    boundaries = find_boundaries(labels_crop, mode='thick')\n",
    "    overlay_crop[boundaries] = [255, 255, 0]  # Yellow boundaries\n",
    "    axes[i, 2].imshow(overlay_crop)\n",
    "    axes[i, 2].set_title(f'Region {i+1} - Cell Boundaries', fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / '02_cell_segmentation_closeup.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs for next notebook\n",
    "np.save(output_dir / 'img_normalized.npy', img_normalized)\n",
    "np.save(output_dir / 'cell_mask.npy', cell_mask)\n",
    "np.save(output_dir / 'cell_labels.npy', cell_labels)\n",
    "\n",
    "if markers:\n",
    "    for marker, mask in markers.items():\n",
    "        np.save(output_dir / f'marker_{marker}.npy', mask)\n",
    "\n",
    "print(f'Results saved to {output_dir}')\n",
    "print('\\nReady for notebook 02: Islet Detection & Radial Analysis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isletscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}